{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31e4fde1-2fbe-4d42-8f16-c8d9ac08091a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Zenith Online - Data Transformation Pipeline (Unity Catalog)\n",
    "\n",
    "This notebook implements the full Bronze-Silver-Gold ETL pipeline for Zenith Online, fully integrated with Databricks Unity Catalog. It is designed to be run after the data generator has populated the landing zone volume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b1054b3-09fd-413e-9377-ba3338060988",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pipeline Initialization\n",
    "\n",
    "Import required libraries and set up Spark session. Define all paths and table names for Unity Catalog integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e93317dd-a20d-4aa6-86b3-44b3160f17a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, TimestampType\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd\n",
    "\n",
    "# In Databricks, the SparkSession `spark` is already created for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "744187b5-e68f-4442-aa22-d123854ca7b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# The data generator wrote data to these UC Volume paths\n",
    "RAW_STREAMING_PATH = \"/Volumes/zenith_online/00_landing/streaming/user_events\"\n",
    "RAW_BATCH_CUSTOMERS_PATH = \"/Volumes/zenith_online/00_landing/batch/customers\"\n",
    "RAW_BATCH_PRODUCTS_PATH = \"/Volumes/zenith_online/00_landing/batch/products\"\n",
    "\n",
    "# Define the three-level namespace for Unity Catalog\n",
    "CATALOG_NAME = \"zenith_online\"\n",
    "BRONZE_SCHEMA = \"01_bronze\"\n",
    "SILVER_SCHEMA = \"02_silver\"\n",
    "GOLD_SCHEMA = \"03_gold\"\n",
    "\n",
    "# Define UC Volume paths for streaming checkpoints and schema metadata\n",
    "CHECKPOINT_BASE_PATH = f\"/Volumes/{CATALOG_NAME}/_system/checkpoints\"\n",
    "SCHEMA_BASE_PATH = f\"/Volumes/{CATALOG_NAME}/_system/schemas\"\n",
    "\n",
    "# Full table names\n",
    "BRONZE_EVENTS_TABLE = f\"{CATALOG_NAME}.{BRONZE_SCHEMA}.bronze_user_events\"\n",
    "BRONZE_CUSTOMERS_TABLE = f\"{CATALOG_NAME}.{BRONZE_SCHEMA}.bronze_customer_profiles\"\n",
    "BRONZE_PRODUCTS_TABLE = f\"{CATALOG_NAME}.{BRONZE_SCHEMA}.bronze_product_details\"\n",
    "SILVER_TABLE = f\"{CATALOG_NAME}.{SILVER_SCHEMA}.silver_sessionized_activity\"\n",
    "GOLD_DAILY_PRODUCT_TABLE = f\"{CATALOG_NAME}.{GOLD_SCHEMA}.gold_daily_product_performance\"\n",
    "GOLD_CUSTOMER_SUMMARY_TABLE = f\"{CATALOG_NAME}.{GOLD_SCHEMA}.customer_purchase_summary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5db2c17f-e94a-4442-8411-26f14724108f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Unity Catalog Environment Setup\n",
    "\n",
    "Create the catalog and schemas if they do not exist. This ensures all downstream tables are created in the correct namespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bc03f36-f45b-4bcb-8865-ffb9e8ee77c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create the Catalog and Schemas if they do not exist\n",
    "spark.sql(f\"CREATE CATALOG IF NOT EXISTS {CATALOG_NAME}\")\n",
    "spark.sql(f\"USE CATALOG {CATALOG_NAME}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {BRONZE_SCHEMA}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SILVER_SCHEMA}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {GOLD_SCHEMA}\")\n",
    "\n",
    "print(f\"Unity Catalog environment '{CATALOG_NAME}' is ready.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "df3b2670-6c5c-4891-9b73-e8e150887fc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 01 - Bronze Layer: Raw Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d30d4d82-90ad-409c-8b91-006e61adc710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Streaming User Events\n",
    "Ingest raw user event data from JSON files using Auto Loader and write to a Delta table in the Bronze schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "615976ac-5c8c-4e82-99a0-b96f5e8a6440",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting Bronze Layer: Streaming Events Ingestion\")\n",
    "\n",
    "event_schema = StructType([\n",
    "    StructField(\"event_id\", StringType(), True),\n",
    "    StructField(\"event_timestamp\", StringType(), True),\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"event_type\", StringType(), True),\n",
    "    StructField(\"product_id\", IntegerType(), True),\n",
    "    StructField(\"session_id\", StringType(), True)\n",
    "])\n",
    "\n",
    "bronze_events_df = (\n",
    "    spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"json\")\n",
    "    .option(\"cloudFiles.schemaLocation\", f\"{SCHEMA_BASE_PATH}/bronze_events\")\n",
    "    .schema(event_schema)\n",
    "    .load(RAW_STREAMING_PATH)\n",
    "    .withColumn(\"ingestion_timestamp\", F.current_timestamp())\n",
    "    .withColumn(\"event_dt\", F.to_timestamp(\"event_timestamp\"))\n",
    ")\n",
    "\n",
    "(\n",
    "    bronze_events_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", f\"{CHECKPOINT_BASE_PATH}/bronze_events\")\n",
    "    .trigger(availableNow=True) \n",
    "    .toTable(BRONZE_EVENTS_TABLE)\n",
    ")\n",
    "\n",
    "print(f\"Bronze Layer: Streaming events processing complete. Table `{BRONZE_EVENTS_TABLE}` is updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e9660ba-b11d-48bd-be0f-fa5f2631c7cc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Batch Customer & Product Data\n",
    "Ingest customer profiles (CSV) and product details (Parquet) into Bronze tables for further enrichment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "197c1751-6838-4a94-a273-3b232ccb734a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting Bronze Layer: Batch Ingestion\")\n",
    "\n",
    "customer_schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), False),\n",
    "    StructField(\"signup_date\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True)\n",
    "])\n",
    "customers_df = spark.read.format(\"csv\").schema(customer_schema).option(\"header\", \"true\").load(RAW_BATCH_CUSTOMERS_PATH)\n",
    "customers_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(BRONZE_CUSTOMERS_TABLE)\n",
    "print(f\"Bronze Layer: Wrote customer profiles to `{BRONZE_CUSTOMERS_TABLE}`.\")\n",
    "\n",
    "products_df = spark.read.format(\"parquet\").load(RAW_BATCH_PRODUCTS_PATH)\n",
    "products_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(BRONZE_PRODUCTS_TABLE)\n",
    "print(f\"Bronze Layer: Wrote product details to `{BRONZE_PRODUCTS_TABLE}`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c904904c-2ee1-414d-ad77-2707264ee1a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 02 - Silver Layer - Clean, Enrich, and De-duplicate\n",
    "\n",
    "**Goal:** Read from the Bronze UC tables, enrich the data, and write the cleaned result to a Silver UC table (`zenith_online.02_silver.silver_sessionized_activity`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f108aaaa-d295-46cb-bd57-3d1ca143aa42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Define Region Categorization Logic\n",
    "\n",
    "Create a Pandas UDF to categorize customer locations into regions for downstream analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4aecad23-a665-49dc-a276-0efa4602afd5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@F.pandas_udf(StringType())\n",
    "def categorize_region(locations: pd.Series) -> pd.Series:\n",
    "    east_coast = ['New York', 'Philadelphia']\n",
    "    west_coast = ['Los Angeles', 'San Diego']\n",
    "    def get_region(location):\n",
    "        if location in east_coast: return 'East Coast'\n",
    "        elif location in west_coast: return 'West Coast'\n",
    "        else: return 'Central'\n",
    "    return locations.apply(get_region)\n",
    "\n",
    "print(\"Silver Layer: Pandas UDF `categorize_region` created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "333475ef-419d-450e-8e2e-866f94850a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Silver Layer Transformation\n",
    "\n",
    "Deduplicate streaming events, join with customer and product data, enrich with region, and write to the Silver Delta table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f103c833-6f22-4cac-8267-5bedf07fdab4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting Silver Layer: Enriching and Cleaning Events\")\n",
    "\n",
    "bronze_events_stream_df = spark.readStream.table(BRONZE_EVENTS_TABLE)\n",
    "customers_df = spark.read.table(BRONZE_CUSTOMERS_TABLE)\n",
    "products_df = spark.read.table(BRONZE_PRODUCTS_TABLE)\n",
    "\n",
    "deduplicated_stream_df = (\n",
    "    bronze_events_stream_df\n",
    "        .withWatermark(\"event_dt\", \"3 minutes\")\n",
    "        .dropDuplicates([\"event_id\"])\n",
    ")\n",
    "\n",
    "enriched_df = (\n",
    "    deduplicated_stream_df\n",
    "    .join(\n",
    "        F.broadcast(products_df), \n",
    "        deduplicated_stream_df.product_id == products_df.product_id,\n",
    "        \"inner\"\n",
    "    )\n",
    "    .join(\n",
    "        customers_df,\n",
    "        deduplicated_stream_df.user_id == customers_df.customer_id,\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\"region\", categorize_region(F.col(\"location\")))\n",
    "    .withColumnRenamed(\"event_type\", \"action\")\n",
    "    .withColumn(\"event_date\", F.to_date(F.col(\"event_dt\")))\n",
    "    .select(\n",
    "        \"event_id\", \"event_dt\", \"event_date\", \"action\",\n",
    "        deduplicated_stream_df.user_id, \"region\",\n",
    "        deduplicated_stream_df.product_id, \"product_name\", \"category\", \"price\"\n",
    "    )\n",
    ")\n",
    "\n",
    "(\n",
    "    enriched_df.writeStream\n",
    "    .format(\"delta\")\n",
    "    .outputMode(\"append\")\n",
    "    .option(\"checkpointLocation\", f\"{CHECKPOINT_BASE_PATH}/silver_activity\")\n",
    "    .trigger(availableNow=True)\n",
    "    .toTable(SILVER_TABLE)\n",
    ")\n",
    "\n",
    "print(f\"Silver Layer: Enriched activity stream processing complete. Table `{SILVER_TABLE}` is updated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f24ab943-c19b-463e-8734-9c6e2b1daadd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 03 - Gold Layer: Business-Focused Aggregations\n",
    "\n",
    "Produce analytics-ready tables for business intelligence and reporting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5b94112-60a6-4bd7-8a6f-770f7daa7c8d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Daily Product Performance (Handling Data Skew)\n",
    "\n",
    "Aggregate Silver data to compute daily product metrics, using salting to mitigate data skew for popular products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0efab8b0-c4ef-46f6-81b4-503da4e44e90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting Gold Layer: Daily Product Performance Aggregation\")\n",
    "silver_df = spark.read.table(SILVER_TABLE)\n",
    "\n",
    "SALTING_FACTOR = 5\n",
    "salted_df = silver_df.withColumn(\"salt\", (F.rand() * SALTING_FACTOR).cast(\"int\"))\n",
    "\n",
    "salted_agg_df = (\n",
    "    salted_df.groupBy(\"event_date\", \"product_id\", \"product_name\", \"category\", \"salt\")\n",
    "    .agg(\n",
    "        F.count(F.when(F.col(\"action\") == \"view_product\", 1)).alias(\"views\"),\n",
    "        F.count(F.when(F.col(\"action\") == \"add_to_cart\", 1)).alias(\"adds_to_cart\"),\n",
    "        F.count(F.when(F.col(\"action\") == \"purchase\", 1)).alias(\"purchases\"),\n",
    "        F.sum(F.when(F.col(\"action\") == \"purchase\", F.col(\"price\")).otherwise(0)).alias(\"daily_revenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "daily_product_performance_df = (\n",
    "    salted_agg_df.groupBy(\"event_date\", \"product_id\", \"product_name\", \"category\")\n",
    "    .agg(\n",
    "        F.sum(\"views\").alias(\"total_views\"),\n",
    "        F.sum(\"adds_to_cart\").alias(\"total_adds_to_cart\"),\n",
    "        F.sum(\"purchases\").alias(\"total_purchases\"),\n",
    "        F.sum(\"daily_revenue\").alias(\"total_revenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "window_spec = Window.partitionBy(\"event_date\", \"category\").orderBy(F.col(\"total_revenue\").desc())\n",
    "final_product_gold_df = daily_product_performance_df.withColumn(\"revenue_rank\", F.rank().over(window_spec))\n",
    "\n",
    "(\n",
    "    final_product_gold_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .option(\"overwriteSchema\", \"true\")\n",
    "    .partitionBy(\"event_date\")\n",
    "    .saveAsTable(GOLD_DAILY_PRODUCT_TABLE)\n",
    ")\n",
    "\n",
    "print(f\"Gold Layer: Wrote to `{GOLD_DAILY_PRODUCT_TABLE}` after handling skew.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca43dd5e-277a-4850-bec9-11c8e04e5b1e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1754083003002}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(final_product_gold_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e4f7c15-d4ae-4667-9199-b878105a54e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Customer Purchase Summary\n",
    "\n",
    "Aggregate customer-level purchase metrics and perform a data quality check for missing regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32eb234d-61b8-4015-9e7e-f2f08aae30b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Starting Gold Layer: Customer Purchase Summary\")\n",
    "silver_df = spark.read.table(SILVER_TABLE)\n",
    "\n",
    "# --- Data Quality Check (Serverless-Compatible Method) ---\n",
    "# # Accumulators are not available on serverless compute as they require direct sparkContext access.\n",
    "# unknown_location_count = spark.sparkContext.accumulator(0)\n",
    "# def count_unknown_locations(region):\n",
    "#     if region is None:\n",
    "#         global unknown_location_count\n",
    "#         unknown_location_count += 1\n",
    "#     return region\n",
    "# count_unknown_udf = F.udf(count_unknown_locations, StringType())\n",
    "# The best practice is to perform a direct count() action on a filtered DataFrame.\n",
    "# This achieves the same goal of gathering a metric from the data.\n",
    "unknown_location_count = silver_df.filter(F.col(\"region\").isNull()).count()\n",
    "\n",
    "print(f\"Data Quality Check: Found {unknown_location_count} events with unknown customer locations.\")\n",
    "\n",
    "customer_summary_df = (\n",
    "    silver_df.filter(F.col(\"action\") == 'purchase')\n",
    "    .groupBy(\"user_id\", \"region\")\n",
    "    .agg(\n",
    "        F.sum(\"price\").alias(\"total_purchase_value\"),\n",
    "        F.count(\"event_id\").alias(\"total_purchases\"),\n",
    "        F.approx_count_distinct(\"product_id\").alias(\"distinct_products_purchased\"),\n",
    "        F.max(\"event_dt\").alias(\"last_purchase_timestamp\")\n",
    "    )\n",
    "    .orderBy(F.col(\"total_purchase_value\").desc())\n",
    ")\n",
    "\n",
    "(\n",
    "    customer_summary_df.write\n",
    "    .format(\"delta\")\n",
    "    .mode(\"overwrite\")\n",
    "    .saveAsTable(GOLD_CUSTOMER_SUMMARY_TABLE)\n",
    ")\n",
    "print(f\"Gold Layer: Wrote to `{GOLD_CUSTOMER_SUMMARY_TABLE}`.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6482ee41-e2ef-4dfc-8334-086e929b9bd1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Answering Business Questions\n",
    "\n",
    "Now that our Gold tables exist in Unity Catalog, we can query them directly with SQL.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57e2ba29-4370-4754-9945-9560a9923ca9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Business Question 1: What are the top 5 most purchased products for the most recent day?\n",
    "\n",
    "Query the Gold product performance table to find the most popular products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9ea7f6f-7ffa-44fa-acda-c677979a102a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Top 5 Purchased Products (Most Recent Day) ---\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        event_date,\n",
    "        product_name,\n",
    "        category,\n",
    "        total_purchases,\n",
    "        total_revenue\n",
    "    FROM {GOLD_DAILY_PRODUCT_TABLE}\n",
    "    --WHERE event_date = (SELECT MAX(event_date) FROM {GOLD_DAILY_PRODUCT_TABLE})\n",
    "    ORDER BY total_purchases DESC\n",
    "    LIMIT 5\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c09958ac-45bb-43c4-a4db-cf75272ef19d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Business Question 2: What is the daily sales revenue per category?\n",
    "\n",
    "Summarize daily revenue by product category for trend analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb689a06-fee5-4469-8df4-16eebcfe600a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Daily Sales Revenue per Category ---\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        event_date,\n",
    "        category,\n",
    "        SUM(total_revenue) as category_revenue\n",
    "    FROM {GOLD_DAILY_PRODUCT_TABLE}\n",
    "    GROUP BY event_date, category\n",
    "    ORDER BY event_date DESC, category_revenue DESC\n",
    "\"\"\").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e41ac80f-b2ac-43e7-b943-6419f58237a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Top 10 Customers by Purchase Value\n",
    "\n",
    "Identify the highest-value customers based on total purchase value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a368eb58-57b2-4263-b7ef-f2ddaab453e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"--- Top 10 Customers by Purchase Value ---\")\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT\n",
    "        user_id,\n",
    "        region,\n",
    "        total_purchase_value,\n",
    "        total_purchases,\n",
    "        last_purchase_timestamp\n",
    "    FROM {GOLD_CUSTOMER_SUMMARY_TABLE}\n",
    "    ORDER BY total_purchase_value DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3232a62f-e55e-40fa-8583-4d8dc0f7060a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## End of Pipeline\n",
    "\n",
    "The script has successfully processed data through the Bronze, Silver, and Gold layers within Unity Catalog, creating valuable business assets and demonstrating key capabilities tested in the Spark Developer certification exam."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ELT",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}